{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82cdcffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba42379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d886f47c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2719477080.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_869/2719477080.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    text = [p.text for p in soup.find(class=\"elementor-element elementor-element-74af9a5b elementor-widget elementor-widget-theme-post-content\").find_all('p')]\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def url_to_transcript(url):\n",
    "    \"\"\"Returns transcript data specifically from scrapsfromtheloft.com\"\"\"\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "    text = [p.text for p in soup.find(class=\"elementor-element elementor-element-74af9a5b elementor-widget elementor-widget-theme-post-content\").find_all('p')]\n",
    "    print(url)\n",
    "    return text\n",
    "\n",
    "# URLs of transcript in space\n",
    "urls = [\"http://scrapsfromtheloft.com/2017/05/06/louis-ck-oh-my-god-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/04/11/dave-chappelle-age-spin-2017-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2018/03/15/ricky-gervais-humanity-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/08/07/bo-burnham-2013-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/05/24/bill-burr-im-sorry-feel-way-2014-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/04/21/jim-jefferies-bare-2014-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/08/02/john-mulaney-comeback-kid-2015-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/10/21/hasan-minhaj-homecoming-king-2017-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/09/19/ali-wong-baby-cobra-2016-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/08/03/anthony-jeselnik-thoughts-prayers-2015-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2018/03/03/mike-birbiglia-my-girlfriends-boyfriend-2013-full-transcript/\",\n",
    "       \"http://scrapsfromtheloft.com/2017/08/19/joe-rogan-triggered-2016-full-transcript/\"]\n",
    "\n",
    "# Comedian names\n",
    "comedians = [\"louis\",\"dave\",\"ricky\",\"bo\",\"bill\",\"jim\",\"john\",\"hasan\",\"ali\",\"anthony\",\"mike\",\"joe\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8d72f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_869/3962868995.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranscripts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0murl_to_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'urls' is not defined"
     ]
    }
   ],
   "source": [
    "transcripts = [url_to_transcript(u) for u in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "169328d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: transcripts: File exists\r\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'comedians' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_869/4245489850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir transcripts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomedians\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transcripts/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscripts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comedians' is not defined"
     ]
    }
   ],
   "source": [
    "!mkdir transcripts\n",
    "\n",
    "for i, c in enumerate(comedians):\n",
    "    with open(\"transcripts/\" + c + \".txt\",\"wb\") as file:\n",
    "        pickle.dumb(transcripts[i], file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b881aeea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comedians' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_869/2705411095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomedians\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transcripts/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comedians' is not defined"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i, c in enumerate(comedians):\n",
    "    with open(\"transcripts/\" + c + \".txt\",\"rb\") as file:\n",
    "        data[c] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c809e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0692d361",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'louis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_869/2676810929.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"louis\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'louis'"
     ]
    }
   ],
   "source": [
    "data[\"louis\"][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8c578",
   "metadata": {},
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b34cc",
   "metadata": {},
   "source": [
    "#Common Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8b089",
   "metadata": {},
   "source": [
    "- Make text all lower case\n",
    "- Remove punctuation\n",
    "- Remove numerical values\n",
    "- Remove common non-sensical text (/n)\n",
    "- Tokenize text\n",
    "- Remove stop words\n",
    "- Stemming / lemmatization\n",
    "- Parts of speech tagging\n",
    "- Create bi-grams or tri-grams\n",
    "- Deal with typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ba643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(list_of_text):\n",
    "    \"\"\"Takes a list of text and combines them into one large chunk of text.\"\"\"\n",
    "    combined_text=\" \".join(list_of_text)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a05c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = {key: [combine_text(value)] for (key, value) in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"max-coldwith\",150)\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(data_combined).transpose()\n",
    "data_df.columns = [\"transcript\"]\n",
    "data_df = data_df.sort_index()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fc1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.transcript.loc[\"ali\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    text= text.lower()\n",
    "    text= re.sub(\"\\[.*?\\]\",\"\",text)\n",
    "    text= re.sub(\"[%s]\" % re.escape(string.punctuation),\"\",text)\n",
    "    text= re.sub(\"\\w*\\d\\w*\",\"\",text)\n",
    "    text= re.sub(\"[\"\"'']\",\"\",text)\n",
    "    text= re.sub(\"\\n\",\"\",text)\n",
    "    return text\n",
    "    \n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af921410",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame(data_df.transcript.apply(round1))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551aabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle(\"corpus.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5d130",
   "metadata": {},
   "source": [
    "# Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de12169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words = \"english\")\n",
    "data_cv = cv.fit_transform(data_clean.transcript)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(),columns=cv.get_feature_names())\n",
    "data_dtm.index = data_clean.index()\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtm.to_pickel(\"dtm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa281eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_pickle(\"data_clean.pkl\")\n",
    "pickle.dump(cv, open(\"cv.pkl\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
