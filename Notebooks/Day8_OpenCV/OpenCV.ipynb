{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea49d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d14cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input = cv2.imread(\"input.jpg\")\n",
    "cv2.imshow(\"Hello World\",input)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bcadf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "checkBoard = np.zeros((8,8))\n",
    "checkBoard[0::2,1::2]=1\n",
    "checkBoard[1::2,0::2]=1\n",
    "\n",
    "print(checkBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plt.imshow(checkBoard,cmap=\"gray\",interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f45fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "image_of_a_bush = data.lfw_subset()\n",
    "image_of_a_bush = image_of_a_bush[0,:,:]\n",
    "print(image_of_a_bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ef852",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image_of_a_bush,cmap=\"gray\",interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edeb51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.astronaut()\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60930c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"input.jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.waitKey()\n",
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Grayscale\",gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tek satırda siyah-beyaz okumak için\n",
    "image = cv2.imread(\"input.jpg\",0)\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b630b3f",
   "metadata": {},
   "source": [
    "# Understanding COLOR_BGR2GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "image = cv2.imread(\"input.jpg\")\n",
    "\n",
    "B,G,R = image[0,0]\n",
    "B,G,R = image[10,50]\n",
    "\n",
    "print(B,G,R)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c41be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "print(gray_img.shape)\n",
    "print(gray_img[10,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26240a09",
   "metadata": {},
   "outputs": [],
   "source": [
    " gray_img[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed73d2",
   "metadata": {},
   "source": [
    "# HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301077d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "hsv_image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV image\",hsv_image)\n",
    "cv2.imshow(\"Hue channel\",hsv_image[:,:,0])\n",
    "cv2.imshow(\"Saturation channel\",hsv_image[:,:,1])\n",
    "cv2.imshow(\"Calue channel\",hsv_image[:,:,2])\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528611b1",
   "metadata": {},
   "source": [
    "# RGB İmage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fe97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "\n",
    "B,G,R = cv2.split(image)\n",
    "\n",
    "print(B.shape)\n",
    "cv2.imshow(\"Red\",R)\n",
    "cv2.imshow(\"Green\",G)\n",
    "cv2.imshow(\"Blue\",B)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "merged = cv2.merge([B,G,R])\n",
    "cv2.imshow(\"Merged\",merged)\n",
    "\n",
    "merged = cv2.merge([B+100,G,R+100])\n",
    "cv2.imshow(\"Merged with Blue Amplified\",merged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d3aa96",
   "metadata": {},
   "source": [
    "# Image Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "quareter_height, quareter_width = height/4, width/4\n",
    "\n",
    "T = np.float32([[1,0,quareter_width],[0,1,quareter_height]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image,T,(width,height))\n",
    "cv2.imshow(\"Translation\",img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffdd03",
   "metadata": {},
   "source": [
    "# Transform Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2),45,.5)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "\n",
    "cv2.imshow(\"Rotated Image\",rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6630635",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\",0)\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "sobel_x = cv2.Sobel(image,cv2.CV_64F,0,1,ksize=5)\n",
    "sobel_y = cv2.Sobel(image,cv2.CV_64F,1,0,ksize=5)\n",
    "\n",
    "cv2.imshow(\"Rotated İmage\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Sobel X\",sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"sobel_y\",sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow(\"sobel_OR\",sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "cv2.imshow(\"Laplacian\",laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image,50,120)\n",
    "cv2.imshow(\"Canny\",canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1133393a",
   "metadata": {},
   "source": [
    "# Live Sketch Using Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch(image):\n",
    "    img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0) \n",
    "    canny_edges = cv2.Canny(img_gray_blur,10,70)\n",
    "    ret,mask = cv2.threshold(canny_edges,70,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow(\"Our live Sketcher\",sketch(frame))\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eaedff",
   "metadata": {},
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"WaldoBeach.jpg\")\n",
    "\n",
    "cv2.imshow(\"Where is Waldo\",image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "template = cv2.imread(\"waldo.jpg\",0)\n",
    "\n",
    "result = cv2.matchTemplate(gray,template,cv2.TM_CCOEFF)\n",
    "minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(result)\n",
    "\n",
    "top_left = maxLoc\n",
    "bottom_right = (top_left[0]+50, top_left[1]+50)\n",
    "cv2.rectangle (image,top_left,bottom_right,(0,0,255),5)\n",
    "\n",
    "cv2.imshow(\"Where is Waldo\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7fd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "\n",
    "image = cv2.imread(\"input.jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "\n",
    "flipped = cv2.flip(image,0)\n",
    "cv2.imshow(\"Vertical Flip\",flipped)\n",
    "\n",
    "flipped = cv2.flip(image,1)\n",
    "cv2.imshow(\"Horizontal Flip\",flipped)\n",
    "\n",
    "flipped = cv2.flip(image,-1)\n",
    "cv2.imshow(\"Bot Flip\",flipped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bcf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Demo\",frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Ergimiş Metal\",frame)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "        cv2.imshow(\"Demo\",frame)\n",
    "        cv2.imshow(\"Gray\",gray)\n",
    "        cv2.imshow(\"HSV\",hsv)\n",
    "    else:\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur, frame2_blur)\n",
    "\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "        \n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur, frame2_blur)\n",
    "\n",
    "    thresh = cv2.threshold(diff,20,255,cv2.THRESH_BINARY)[1]\n",
    "    final = cv2.dilate(thresh,None,iterations = 2)\n",
    "    \n",
    "    cv2.imshow(\"Motion\",thresh)\n",
    "    frame1 = frame2\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    key = cv2.waitKey(10)\n",
    "    if (key == 27) or (key == ord(\"q\")):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ee7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_blur, frame2_blur)\n",
    "\n",
    "    thresh = cv2.threshold(diff,20,255,cv2.THRESH_BINARY)[1]\n",
    "    final = cv2.dilate(thresh,None,iterations = 2)\n",
    "    \n",
    "    masked = cv2.bitwise_and(frame1,frame1,mask=thresh)\n",
    "    \n",
    "    white_pixels = np.sum(thresh) / 255\n",
    "    \n",
    "    rows,cols = thresh.shape\n",
    "    total = rows*cols\n",
    "    \n",
    "    if white_pixels > 0.01 * total:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame1,\"Movement Detected - Hareket Var\",(10,50),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Motion\",frame1)\n",
    "    frame1 = frame2\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    key = cv2.waitKey(10)\n",
    "    if (key == 27) or (key == ord(\"q\")):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335a8c3",
   "metadata": {},
   "source": [
    "# Contours in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bbcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"box_in_scene.png\")\n",
    "cv2.imshow(\"Input Image\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edged = cv2.Canny(gray,30,200)\n",
    "cv2.imshow(\"Canny Edges\",edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow(\"Canny Edges After Contouring\", edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \"+ str(len(contours)))\n",
    "\n",
    "cv2.drawContours(image, contours, -1 (0,255,0),thickness = 2)\n",
    "\n",
    "cv2.imshow(\"Contours\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.waitKey(0)\n",
    "# Grayscale and Canny Edges Extracted\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize= 3)\n",
    "\n",
    "# Run HoughLines using a rho accuracy of 1 pixel\n",
    "# Theta accuracy of np.pi / 180 which is 1 degree\n",
    "# Our line threshold is set to 240 (number of points on line)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi /180, 240)\n",
    "\n",
    "# We iterate through each line and convert it to the format\n",
    "# Required vby cv2.lines (i.e. requiring end points)\n",
    "\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1,y1),(x2,y2),(255,0,0),2)\n",
    "\n",
    "cv2.imshow(\"Hough Lines\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"opencv.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT,1.5,20)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(image,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    \n",
    "    # draw the center of the circle\n",
    "    cv2.circle(image,(i[0],i[1]),2,(0,255,0),2)\n",
    "\n",
    "\n",
    "cv2.imshow(\"detected circles\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf84712",
   "metadata": {},
   "source": [
    "# Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard İmports \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read Image\n",
    "image = cv2.imread(\"sunflowers.jpg\")\n",
    "\n",
    "# Set up the detector with default parameters.\n",
    "detector = cv2.SimpleBlobDetector_create()\n",
    "\n",
    "# Detect Blobs.\n",
    "keypoints = detector.detect(image)\n",
    "\n",
    "# Draw detected blobs as red circles.\n",
    "blank = np.zeros((1,1))\n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0), cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    "\n",
    "# Sk-how keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f6eae6",
   "metadata": {},
   "source": [
    "# Face and Eye Detection with HAAR Cascade Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "\n",
    "# We point OpenCV's CascadeClassifier function to where our\n",
    "# Classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "image = cv2.imread(\"DSC_9810.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Our classifier returns the ROI of the detected face as a tuple\n",
    "# It stores the top left coordinate and the bottom right coordinates\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected , face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "    \n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (127, 0, 255), 2)\n",
    "    cv2.imshow(\"Face Detection\", image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb5944",
   "metadata": {},
   "source": [
    "# Let's combine face and eye detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2506216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_15567/3931427759.py:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_classifier =  cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "img = cv2.imread(\"DSC_9810.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No Face Found\")\n",
    "    \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow(\"img\",img)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n",
    "        cv2.imshow(\"img\",img)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e1db63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_15567/2267416371.py:12: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_15567/2267416371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Our Face Extractor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#13 is the enter key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_15567/2267416371.py\u001b[0m in \u001b[0;36mface_detector\u001b[0;34m(img, size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Convert image to gray scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from time import sleep \n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_classifier =  cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "def face_detector(img,size=0.5):\n",
    "    # Convert image to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        x = x - 50\n",
    "        w = w + 50\n",
    "        y = y - 50\n",
    "        h = h + 50\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        sleep(.05)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n",
    "\n",
    "    img = cv2.flip(img,1)\n",
    "    return img \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Our Face Extractor\",face_detector(frame))\n",
    "    if cv2.waitKey(1) == 13: #13 is the enter key\n",
    "        break\n",
    "        \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9009d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_15567/656944996.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Face Not Found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path = \"./faces/user/\" + str(count) + \".jpg\"\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        \n",
    "        cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0),2)\n",
    "        cv2.imshow(\"Face Cropper\",face)\n",
    "    else:\n",
    "        print(\"Face Not Found\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1) == 13 or count == 100:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81cf7602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained Succesfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "\n",
    "data_path = \"./faces/user/\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "Training_Data,Labels = [],[]\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images,dtype = np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "Labels = np.asarray(Labels,dtype = np.int32)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data),np.asarray(Labels))\n",
    "print(\"Model Trained Succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "987e174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_15567/4232194759.py:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def face_extractor(img, size = 0.5):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return img,[]\n",
    "    \n",
    "    for (x,y,w,h) in faces :\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image,face = face_extractor(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        results = model.predict(face)\n",
    "        \n",
    "        if results[1]<500:\n",
    "            confidence = int(100 * (1-(results[1])/400))\n",
    "            display_string = str(confidence) + \"% Confident it is MBE\"\n",
    "            \n",
    "        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX,1,(255,120,150),2)\n",
    "        \n",
    "        if confidence > 75:\n",
    "            cv2.putText(image,\"Unlocked\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow(\"Face Recognition\",image)\n",
    "        else:\n",
    "            cv2.putText(image,\"Locked\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow(\"Face Recognition\",image)\n",
    "    except:\n",
    "        cv2.putText(image,\"No Face Found\",(220,120),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,\"Locked\",(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.imshow(\"Face Recogniiton\",image)\n",
    "        \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        cap.release()\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58319974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
