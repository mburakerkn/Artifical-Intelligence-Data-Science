{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a15e63b",
   "metadata": {},
   "source": [
    "# Predicting Molecular Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f981b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d9ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict()\n",
    "\n",
    "df['train'] = pd.read_csv('train.csv', index_col='id')\n",
    "df['infer'] = pd.read_csv('test.csv', index_col='id')\n",
    "df['structure'] = pd.read_csv('structures.csv')\n",
    "df['charges'] = pd.read_csv('mulliken_charges.csv')\n",
    "\n",
    "# merge both datasets\n",
    "df['full'] = pd.concat([df['train'], df['infer']], axis=0, sort=False)\n",
    "\n",
    "# free up some memory\n",
    "del df['train'], df['infer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c809fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'full'\n",
    "\n",
    "for atom in [0,1]:\n",
    "\n",
    "    # adding atom coordinates\n",
    "    df[key] = pd.merge(df[key], df['structure'], how = 'left',\n",
    "                        left_on  = ['molecule_name', f'atom_index_{atom}'],\n",
    "                        right_on = ['molecule_name',  'atom_index'], \n",
    "                    )\n",
    "\n",
    "    df[key] = df[key].drop('atom_index', axis=1)\n",
    "    df[key] = df[key].rename(columns={\n",
    "                            'atom': f'A{atom}',\n",
    "                            'x': f'x{atom}',\n",
    "                            'y': f'y{atom}',\n",
    "                            'z': f'z{atom}'})\n",
    "\n",
    "# adding number of atoms in a molecule\n",
    "df[key] = pd.merge(df[key], pd.DataFrame(df['structure'].groupby('molecule_name')['atom_index'].max()), how='left',\n",
    "                   left_on='molecule_name', right_on='molecule_name')\n",
    "df[key] = df[key].rename(columns={'atom_index' : 'nAtoms'})\n",
    "\n",
    "# adding bond type\n",
    "df[key].loc[:, 'bond'] = [value[:2] for value in df[key]['type'].values]\n",
    "\n",
    "# adding atom pair\n",
    "df[key].loc[:, 'pair'] = [value[2:] for value in df[key]['type'].values]\n",
    "\n",
    "# adding distances between atoms\n",
    "df[key]['L2'] = np.linalg.norm(df[key][['x0', 'y0', 'z0']].values - \\\n",
    "                               df[key][['x1', 'y1', 'z1']].values, ord=2, axis=1)\n",
    "df[key]['L1'] = np.linalg.norm(df[key][['x0', 'y0', 'z0']].values - \\\n",
    "                               df[key][['x1', 'y1', 'z1']].values, ord=1, axis=1)\n",
    "\n",
    "# adding distance components between atoms\n",
    "df[key].loc[:, 'dx'] = np.abs(df[key].loc[:, 'x0'] - df[key].loc[:, 'x1'])\n",
    "df[key].loc[:, 'dy'] = np.abs(df[key].loc[:, 'y0'] - df[key].loc[:, 'y1'])\n",
    "df[key].loc[:, 'dz'] = np.abs(df[key].loc[:, 'z0'] - df[key].loc[:, 'z1'])\n",
    "\n",
    "# adding relative (to the molecule) L1/L2 distance\n",
    "df[key].loc[:, 'L1_RM'] = df[key].loc[:, 'L1'] / df[key].groupby('molecule_name')['L1'].transform('max')\n",
    "df[key].loc[:, 'L2_RM'] = df[key].loc[:, 'L2'] / df[key].groupby('molecule_name')['L2'].transform('max')\n",
    "\n",
    "# adding relative (to the atom) L1/L2 distance\n",
    "df[key].loc[:, 'L1_RA'] = df[key].loc[:, 'L1'] / df[key].groupby('A1')['L1'].transform('max')\n",
    "df[key].loc[:, 'L2_RA'] = df[key].loc[:, 'L2'] / df[key].groupby('A1')['L2'].transform('max')\n",
    "\n",
    "# adding relative (to the bond) L1/L2 distance\n",
    "df[key].loc[:, 'L1_RB'] = df[key].loc[:, 'L1'] / df[key].groupby('bond')['L1'].transform('max')\n",
    "df[key].loc[:, 'L2_RB'] = df[key].loc[:, 'L2'] / df[key].groupby('bond')['L2'].transform('max')\n",
    "\n",
    "# adding relative (to the type) L1/L2 distance\n",
    "df[key].loc[:, 'L1_RT'] = df[key].loc[:, 'L1'] / df[key].groupby('type')['L1'].transform('max')\n",
    "df[key].loc[:, 'L2_RT'] = df[key].loc[:, 'L2'] / df[key].groupby('type')['L2'].transform('max')\n",
    "\n",
    "# adding molecule reference volume\n",
    "volumes = np.prod(df['structure'].groupby('molecule_name')[['x','y','z']].max() - \\\n",
    "                  df['structure'].groupby('molecule_name')[['x','y','z']].min(), axis=1)\n",
    "\n",
    "volumes = pd.DataFrame(volumes)\n",
    "\n",
    "df[key] = pd.merge(df[key], volumes, how='left', left_on='molecule_name', right_index=True)\n",
    "df[key] = df[key].rename(columns={0 : 'volume'})\n",
    "\n",
    "del volumes\n",
    "\n",
    "# adding molecule reference sizes\n",
    "size = df['structure'].groupby('molecule_name')[['x','y','z']].max() - \\\n",
    "       df['structure'].groupby('molecule_name')[['x','y','z']].min()\n",
    "\n",
    "size = pd.DataFrame(size)\n",
    "\n",
    "df[key] = pd.merge(df[key], size, how='left', left_on='molecule_name', right_index=True)\n",
    "df[key] = df[key].rename(columns={'x':'Lx', 'y':'Ly', 'z':'Lz'})\n",
    "\n",
    "del size\n",
    "\n",
    "# adding molecule weights\n",
    "atomic_weights = {\n",
    "    'H' : 1.008,\n",
    "    'C' : 12.011,\n",
    "    'N' : 14.007,\n",
    "    'O' : 15.999,\n",
    "    'F' : 18.998\n",
    "}\n",
    "\n",
    "def weight(element):\n",
    "    return atomic_weights[element]\n",
    "\n",
    "df['structure'].loc[:, 'atomic_weight'] = list(map(weight, df['structure']['atom']))\n",
    "\n",
    "weights = df['structure'].groupby('molecule_name')['atomic_weight'].sum()\n",
    "weights = pd.DataFrame(weights)\n",
    "\n",
    "df[key] = pd.merge(df[key], weights, how='left', left_on='molecule_name', right_index=True)\n",
    "df[key] = df[key].rename(columns={'atomic_weight' : 'weight'})\n",
    "\n",
    "del weights\n",
    "\n",
    "# adding individual atomic weights\n",
    "df[key].loc[:, 'weightAtom'] = list(map(weight, df[key]['A1']))\n",
    "\n",
    "# adding some feature crosses\n",
    "df[key].loc[:, 'wA/w'] = df[key].loc[:, 'weightAtom'] / df[key].loc[:, 'weight'] \n",
    "df[key].loc[:, 'L1/Lx'] = df[key].loc[:, 'L1'] / df[key].loc[:, 'Lx']\n",
    "df[key].loc[:, 'L2/Lx'] = df[key].loc[:, 'L2'] / df[key].loc[:, 'Lx']\n",
    "df[key].loc[:, 'L1/Ly'] = df[key].loc[:, 'L1'] / df[key].loc[:, 'Ly']\n",
    "df[key].loc[:, 'L2/Ly'] = df[key].loc[:, 'L2'] / df[key].loc[:, 'Ly']\n",
    "df[key].loc[:, 'L1/Lz'] = df[key].loc[:, 'L1'] / df[key].loc[:, 'Lz']\n",
    "df[key].loc[:, 'L2/Lz'] = df[key].loc[:, 'L2'] / df[key].loc[:, 'Lz']\n",
    "df[key].loc[:, 'dx/Lx'] = df[key].loc[:, 'dx'] / df[key].loc[:, 'Lx']\n",
    "df[key].loc[:, 'dy/Ly'] = df[key].loc[:, 'dy'] / df[key].loc[:, 'Ly']\n",
    "df[key].loc[:, 'dz/Lz'] = df[key].loc[:, 'dz'] / df[key].loc[:, 'Lz']\n",
    "df[key].loc[:, 'dx/Lx_RB'] = df[key].loc[:, 'dx'] / df[key].groupby('bond')['Lx'].transform('max')\n",
    "df[key].loc[:, 'dy/Ly_RB'] = df[key].loc[:, 'dy'] / df[key].groupby('bond')['Ly'].transform('max')\n",
    "df[key].loc[:, 'dz/Lz_RB'] = df[key].loc[:, 'dz'] / df[key].groupby('bond')['Lz'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c35208",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "for feature in ['type', 'bond', 'pair']:\n",
    "    df['full'][feature] = encoder.fit_transform(df['full'][feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f655dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dict(), dict()\n",
    "\n",
    "to_drop = [\n",
    "    'A0', 'A1', 'x0', 'y0', 'z0', 'x1', 'y1', 'z1', 'weightAtom', 'scalar_coupling_constant'\n",
    "]\n",
    "\n",
    "X['train'] = df['full'][df['full']['scalar_coupling_constant'].isna() == False].drop(to_drop, axis=1)\n",
    "X['infer'] = df['full'][df['full']['scalar_coupling_constant'].isna() == True].drop(to_drop, axis=1)\n",
    "\n",
    "y['train'] = df['full'][df['full']['scalar_coupling_constant'].isna() == False]['scalar_coupling_constant']\n",
    "\n",
    "X['train'], X['valid'], y['train'], y['valid'] = train_test_split(X['train'], y['train'], \n",
    "                                                                  random_state=0, test_size=0.2)\n",
    "\n",
    "del df['full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57ccfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['train', 'valid']:\n",
    "    X[key] = pd.merge(X[key], df['charges'], how='left',\n",
    "             left_on=['molecule_name', 'atom_index_0'], right_on=['molecule_name', 'atom_index'])\n",
    "\n",
    "    X[key] = X[key].rename(columns={'mulliken_charge':'M0'})\n",
    "\n",
    "    X[key] = pd.merge(X[key], df['charges'], how='left',\n",
    "             left_on=['molecule_name', 'atom_index_1'], right_on=['molecule_name', 'atom_index'])\n",
    "\n",
    "    X[key] = X[key].rename(columns={'mulliken_charge':'M1'})\n",
    "\n",
    "    X[key].drop(['atom_index_x', 'atom_index_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a00c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['train', 'valid', 'infer']:\n",
    "    X[key].drop(['molecule_name', 'atom_index_0', 'atom_index_1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75557fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[17:39:24] /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/data/data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000010fd2b364 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n  [bt] (1) 2   libxgboost.dylib                    0x000000010fd70760 unsigned long long xgboost::SparsePage::Push<xgboost::data::ArrayAdapterBatch>(xgboost::data::ArrayAdapterBatch const&, float, int) + 1440\n  [bt] (2) 3   libxgboost.dylib                    0x000000010fd9bb3a xgboost::data::SimpleDMatrix::SimpleDMatrix<xgboost::data::ArrayAdapter>(xgboost::data::ArrayAdapter*, float, int) + 314\n  [bt] (3) 4   libxgboost.dylib                    0x000000010fd79645 xgboost::DMatrix* xgboost::DMatrix::Create<xgboost::data::ArrayAdapter>(xgboost::data::ArrayAdapter*, float, int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) + 53\n  [bt] (4) 5   libxgboost.dylib                    0x000000010fd29e88 XGDMatrixCreateFromDense + 248\n  [bt] (5) 6   libffi.7.dylib                      0x00000001019adead ffi_call_unix64 + 85\n  [bt] (6) 7   ???                                 0x00007ff7beb3ab40 0x0 + 140702033095488\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0t/_tmyvw0x5yz487l03fhlkrsw0000gn/T/ipykernel_10397/2891863316.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mto_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'M0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'M1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m model0.fit(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'M0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'M0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \"\"\"\n\u001b[1;32m    760\u001b[0m         \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingCallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvalsLog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, label_transform)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m     train_dmatrix = create_dmatrix(\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0meval_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0meval_qid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             \u001b[0mcreate_dmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0menable_categorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_from_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         return _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[0m\u001b[1;32m    773\u001b[0m                                feature_names, feature_types)\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[0;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    312\u001b[0m     data, feature_names, feature_types = _transform_pandas_df(\n\u001b[1;32m    313\u001b[0m         data, enable_categorical, feature_names, feature_types)\n\u001b[0;32m--> 314\u001b[0;31m     return _from_numpy_array(data, missing, nthread, feature_names,\n\u001b[0m\u001b[1;32m    315\u001b[0m                              feature_types)\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_numpy_array\u001b[0;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    176\u001b[0m     }\n\u001b[1;32m    177\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     _check_call(\n\u001b[0m\u001b[1;32m    179\u001b[0m         _LIB.XGDMatrixCreateFromDense(\n\u001b[1;32m    180\u001b[0m             \u001b[0m_array_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \"\"\"\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [17:39:24] /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/data/data.cc:981: Check failed: valid: Input data contains `inf` or `nan`\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000010fd2b364 dmlc::LogMessageFatal::~LogMessageFatal() + 116\n  [bt] (1) 2   libxgboost.dylib                    0x000000010fd70760 unsigned long long xgboost::SparsePage::Push<xgboost::data::ArrayAdapterBatch>(xgboost::data::ArrayAdapterBatch const&, float, int) + 1440\n  [bt] (2) 3   libxgboost.dylib                    0x000000010fd9bb3a xgboost::data::SimpleDMatrix::SimpleDMatrix<xgboost::data::ArrayAdapter>(xgboost::data::ArrayAdapter*, float, int) + 314\n  [bt] (3) 4   libxgboost.dylib                    0x000000010fd79645 xgboost::DMatrix* xgboost::DMatrix::Create<xgboost::data::ArrayAdapter>(xgboost::data::ArrayAdapter*, float, int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) + 53\n  [bt] (4) 5   libxgboost.dylib                    0x000000010fd29e88 XGDMatrixCreateFromDense + 248\n  [bt] (5) 6   libffi.7.dylib                      0x00000001019adead ffi_call_unix64 + 85\n  [bt] (6) 7   ???                                 0x00007ff7beb3ab40 0x0 + 140702033095488\n\n"
     ]
    }
   ],
   "source": [
    "model0 = xgb.XGBRegressor(\n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.2,\n",
    "    max_depth = 9,\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    subsample=0.8,\n",
    "    tree_method='gpu_hist'\n",
    ")\n",
    "\n",
    "to_drop = ['M0', 'M1']\n",
    "\n",
    "model0.fit(\n",
    "    X['train'].drop(to_drop,axis=1), X['train']['M0'], \n",
    "    eval_set=[(X['valid'].drop(to_drop,axis=1), X['valid']['M0'])], \n",
    "    eval_metric='mae',early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea20a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.XGBRegressor(\n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.2,\n",
    "    max_depth = 9,\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    subsample=0.8,\n",
    "    tree_method='gpu_hist'\n",
    ")\n",
    "\n",
    "to_drop = ['M0', 'M1']\n",
    "\n",
    "model1.fit(\n",
    "    X['train'].drop(to_drop,axis=1), X['train']['M1'], \n",
    "    eval_set=[(X['valid'].drop(to_drop,axis=1), X['valid']['M1'])], \n",
    "    eval_metric='mae',early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['infer'].loc[:, 'M0'] = model0.predict(X['infer'])\n",
    "X['infer'].loc[:, 'M1'] = model1.predict(X['infer'].drop('M0', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9066322",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=10000, \n",
    "    learning_rate=0.2,\n",
    "    max_depth = 9,\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    subsample=0.8,\n",
    "    tree_method='gpu_hist'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X['train'], y['train'], \n",
    "    eval_set=[(X['valid'], y['valid'])], \n",
    "    eval_metric='mae',early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dict()\n",
    "\n",
    "predictions['train'] = model.predict(X['train'])\n",
    "predictions['valid'] = model.predict(X['valid'])\n",
    "predictions['infer'] = model.predict(X['infer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc2cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
